{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep AutoVIML for NLP Task.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "u85pMtujIx9k"
      },
      "source": [
        "from deep_autoviml import deep_autoviml as deepauto\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_0NWLslKwVw"
      },
      "source": [
        "BATCHSIZE = 256\n",
        "CLASSES = 10\n",
        "EPOCHS = 25\n",
        "NUM_TRIALS = 5\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoJ7IN5VKyeM"
      },
      "source": [
        "# download dataset from Kaggle: https://www.kaggle.com/arkhoshghalb/twitter-sentiment-analysis-hatred-speech?select=train.csv\n",
        "datapath = 'C:/Users/Ram/Documents/Ram/Data_Sets/'\n",
        "sep = ','\n",
        "filename = 'NLP_small.csv'\n",
        "df = pd.read_csv(datapath+filename,sep=sep)\n",
        "target = 'Sentiment'\n",
        "print(df.shape)\n",
        "df.head(1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bs3nMF0K1oS"
      },
      "source": [
        "df[target].value_counts()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwcdQrpxK4LC"
      },
      "source": [
        "keras_model_type =  \"USE\" ## always try \"auto\" first, then \"basic\", \"deep\", \"BERT\", \"USE\", cnn1\", \"LSTM\" etc.\n",
        "keras_options = {\"early_stopping\": True, 'epochs': 350, 'steps_per_epoch': 15, 'class_weight': True}  ### always set early_stopping to True first and then change it to False\n",
        "model_options = {'tuner':\"storm\", \"max_trials\":10, }\n",
        "\n",
        "## always set the tuner to \"storm\" first and then \"optuna\"\n",
        "#### You always need 15 max_trials to get something decent #####\n",
        "trainfile = datapath+filename\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHgQzX0dK7JH"
      },
      "source": [
        "model, dicti = deepauto.fit(trainfile, target, keras_model_type=keras_model_type, \n",
        "                            project_name='churn_1',\n",
        "                 save_model_flag=False, model_options=model_options,\n",
        "                            keras_options=keras_options, use_my_model='', verbose=2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uhXepH9LI47"
      },
      "source": [
        "filename = 'NLP_small.csv'\n",
        "testfile = datapath+filename\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRxkYTH-LL5N"
      },
      "source": [
        "predictions = deepauto.predict(model, project_name='churn_1', test_dataset=testfile,\n",
        "                                 keras_model_type=keras_model_type, \n",
        "                                 cat_vocab_dict=dicti)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kud7eI-CLQY4"
      },
      "source": [
        "test = pd.read_csv(testfile)\n",
        "predictions[0][:5]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcdyv0u8LQ4d"
      },
      "source": [
        "predictions[1][:5]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJ9BKAEtLSnD"
      },
      "source": [
        "test[target].values[:5]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbHrbY26LVsm"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, mean_absolute_error, mean_squared_error\n",
        "print(classification_report(test[target].values,predictions[1]))\n",
        "#print(np.sqrt(mean_squared_error(test[target].values,predictions[0])))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}