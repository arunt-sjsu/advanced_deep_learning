{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Continual Learning with Avalanche.ipynb","provenance":[],"authorship_tag":"ABX9TyMCNOdX/maXk9xS6cl9kbIi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"PimELWZc0XAF"},"source":["!pip install git+https://github.com/ContinualAI/avalanche.git"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ojMtweKp0RAf"},"source":["from torch.optim import SGD\n","from torch.nn import CrossEntropyLoss\n","from avalanche.benchmarks.classic import SplitMNIST\n","from avalanche.evaluation.metrics import forgetting_metrics, accuracy_metrics, \\\n","    loss_metrics, timing_metrics, cpu_usage_metrics, confusion_matrix_metrics, disk_usage_metrics\n","from avalanche.models import SimpleMLP\n","from avalanche.logging import InteractiveLogger, TextLogger, TensorboardLogger\n","from avalanche.training.plugins import EvaluationPlugin\n","from avalanche.training.strategies import Naive\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ueCewru_z837"},"source":["scenario = SplitMNIST(n_experiences=5)\n","\n","# MODEL CREATION\n","model = SimpleMLP(num_classes=scenario.n_classes)\n","\n","# DEFINE THE EVALUATION PLUGIN and LOGGERS\n","# The evaluation plugin manages the metrics computation.\n","# It takes as argument a list of metrics, collectes their results and returns\n","# them to the strategy it is attached to.\n","\n","# log to Tensorboard\n","tb_logger = TensorboardLogger()\n","\n","# log to text file\n","text_logger = TextLogger(open('log.txt', 'a'))\n","\n","# print to stdout\n","interactive_logger = InteractiveLogger()\n","\n","eval_plugin = EvaluationPlugin(\n","    accuracy_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n","    loss_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n","    timing_metrics(epoch=True, epoch_running=True),\n","    forgetting_metrics(experience=True, stream=True),\n","    cpu_usage_metrics(experience=True),\n","    confusion_matrix_metrics(num_classes=scenario.n_classes, save_image=False,\n","                             stream=True),\n","    disk_usage_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n","    loggers=[interactive_logger, text_logger, tb_logger]\n",")\n","\n","# CREATE THE STRATEGY INSTANCE (NAIVE)\n","cl_strategy = Naive(\n","    model, SGD(model.parameters(), lr=0.001, momentum=0.9),\n","    CrossEntropyLoss(), train_mb_size=500, train_epochs=1, eval_mb_size=100,\n","    evaluator=eval_plugin)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5USiWiO90Lns"},"source":["\n","# TRAINING LOOP\n","print('Starting experiment...')\n","results = []\n","for experience in scenario.train_stream:\n","    print(\"Start of experience: \", experience.current_experience)\n","    print(\"Current Classes: \", experience.classes_in_this_experience)\n","\n","    # train returns a dictionary which contains all the metric values\n","    res = cl_strategy.train(experience)\n","    print('Training completed')\n","\n","    print('Computing accuracy on the whole test set')\n","    # test also returns a dictionary which contains all the metric values\n","    results.append(cl_strategy.eval(scenario.test_stream))\n"],"execution_count":null,"outputs":[]}]}